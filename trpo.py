# -*- coding: utf-8 -*-
"""TRPO.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wBSkL9TrNTb2V5vE3U3S3mnaTaLh0u3c
"""

!apt-get install -y \
    libgl1-mesa-dev \
    libgl1-mesa-glx \
    libglew-dev \
    libosmesa6-dev \
    software-properties-common

!apt-get install -y patchelf

!pip install gym
!pip install free-mujoco-py
!pip install sb3_contrib

!unzip classes.zip

import torch
import gym
import argparse

from classes.env.custom_hopper import *
from sb3_contrib import TRPO
from stable_baselines3.common.evaluation import evaluate_policy

n_episodes = 100000
device = 'cpu'

env_source = gym.make('CustomHopper-source-v0')
env_target = gym.make('CustomHopper-target-v0')

"""
  Training
"""
model = TRPO("MlpPolicy", env_target, learning_rate=1e-3, gamma=0.99, verbose = 0, device = device)
model.learn(total_timesteps=n_episodes, n_eval_episodes = 50, eval_log_path = '/content/trpo')
model.save("trpo_hopper_lr1e-3_100000.mdl")

"""
  Testing
"""

# Evaluate the trained agent
mean_reward, std_reward = evaluate_policy(model, env_source, n_eval_episodes=50)

print(f"mean_reward:{mean_reward:.2f} +/- {std_reward:.2f}")